{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter3_boston_housing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhvnnb0dAKfPiAN8JeX1DT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tzuyichao/python-basic/blob/master/colab/chapter3_boston_housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uul1SgA3Chq8"
      },
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUFK7Bl_EDvT",
        "outputId": "e9ed33be-f261-4d12-fe79-4c32e4caf88d"
      },
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qrcx6pcFO4F",
        "outputId": "c287d987-14c4-4a9a-82ae-cb4b7cdd4d11"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_data.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(404,)\n",
            "(102, 13)\n",
            "(102,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "3l8QJr2LGGDQ",
        "outputId": "0ad26916-1e97-47c4-dc8d-5fc74261a81a"
      },
      "source": [
        "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
        "df = pd.DataFrame(train_data, columns=column_names)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.23247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.142</td>\n",
              "      <td>91.7</td>\n",
              "      <td>3.9769</td>\n",
              "      <td>4.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>18.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02177</td>\n",
              "      <td>82.5</td>\n",
              "      <td>2.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.415</td>\n",
              "      <td>7.610</td>\n",
              "      <td>15.7</td>\n",
              "      <td>6.2700</td>\n",
              "      <td>2.0</td>\n",
              "      <td>348.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>395.38</td>\n",
              "      <td>3.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.89822</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631</td>\n",
              "      <td>4.970</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.3325</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>375.52</td>\n",
              "      <td>3.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.515</td>\n",
              "      <td>6.037</td>\n",
              "      <td>34.5</td>\n",
              "      <td>5.9853</td>\n",
              "      <td>5.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>8.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.69311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.713</td>\n",
              "      <td>6.376</td>\n",
              "      <td>88.4</td>\n",
              "      <td>2.5671</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>391.43</td>\n",
              "      <td>14.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...   RAD    TAX  PTRATIO       B  LSTAT\n",
              "0  1.23247   0.0   8.14   0.0  0.538  ...   4.0  307.0     21.0  396.90  18.72\n",
              "1  0.02177  82.5   2.03   0.0  0.415  ...   2.0  348.0     14.7  395.38   3.11\n",
              "2  4.89822   0.0  18.10   0.0  0.631  ...  24.0  666.0     20.2  375.52   3.26\n",
              "3  0.03961   0.0   5.19   0.0  0.515  ...   5.0  224.0     20.2  396.90   8.01\n",
              "4  3.69311   0.0  18.10   0.0  0.713  ...  24.0  666.0     20.2  391.43  14.65\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1M8hi0nJW3o",
        "outputId": "83b8c01f-3b3b-4957-baeb-c9f9af7de44c"
      },
      "source": [
        "order = np.random.randint(0, 404, size=404)\n",
        "print(order)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[306 299  25  70 387 249 117 253 232 228 239 123  63 338  94 366  36 369\n",
            " 235 191 283 166 121 241 393  44 103 338 198 183  35  18 161  68 363 220\n",
            " 227  99  49  18 208 157 399  81 323 185 104 142 230 125 214  80 255 133\n",
            " 111 158 150  26 378  40  24 260 194 347 184 177  18 201 158 346 351  56\n",
            "  23  41 284  59 287 352 336 266 116 380 303  76  55 243 234 119 207 336\n",
            " 344 324 222 325  70  50 322 369 283  71 360  19 195  40 111 346 119 194\n",
            "  24 144 256 186 267 239 280 377 104 366 153  70  99 148 326 253  64 240\n",
            " 258 117 195 334  72  21 247 117 384 202 122 140 306 373 299 374 305 401\n",
            " 304 340  26 270 385  96 241 205 183 152 167 362 139 243 311  34 306 382\n",
            "  78 356 108 107 380 340 225  25 302  76 396 254  66 277 337 161 299 373\n",
            " 250 163 326  25 286  42 268 184  19 337 301 136 343 350 162 207  81 221\n",
            " 123 179 162 298 135 160 250  24 394 168 133 227  67 210 205  19 379 123\n",
            " 377 215 103 278 114 340 390 154 253 360  30  81  50 151 170 110 371 338\n",
            " 280 203 381 298 166 164 228 118 314 364 253 125  32 128  78  79  68  98\n",
            " 138 258 109 321 245 271  38 284 168 347 249  56 382 317 338 323 397  40\n",
            " 124 163 305 178 356 161 290 391 274  27  46  54 229  23 387 328  69 342\n",
            "  80 185 273  52   2  15 197 311 207 357 327 148 299 134 111 320 130 236\n",
            " 145  63 350 133 179 403 169 287  88  27 128 152 320 278 115 366 253 202\n",
            " 382 195 244  54 320 106  93 231  14 241 202 187 133 374 264  91 168  27\n",
            " 145 162  51   1   9 300 234 246 309 175 263  72 123 265  99 398  45 186\n",
            " 312 249 121  43 387 394 282  84 373 267  57  91 160 310 138 129 164 295\n",
            "  18 352 384  83 141 392 292 240 132 348 372  29 261 236 307 308 151 129\n",
            "  98 194  95 348  69 175 386 318]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU6KYPEXUtAL",
        "outputId": "268b3403-43d1-46b3-b253-d0fbd51c1391"
      },
      "source": [
        "train_data = train_data[order]\n",
        "train_labels = train_labels[order]\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(404,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "zNYx4ch2U52k",
        "outputId": "acb2ff18-4572-469e-a537-f75692da3817"
      },
      "source": [
        "df.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.23247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.142</td>\n",
              "      <td>91.7</td>\n",
              "      <td>3.9769</td>\n",
              "      <td>4.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>18.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02177</td>\n",
              "      <td>82.5</td>\n",
              "      <td>2.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.415</td>\n",
              "      <td>7.610</td>\n",
              "      <td>15.7</td>\n",
              "      <td>6.2700</td>\n",
              "      <td>2.0</td>\n",
              "      <td>348.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>395.38</td>\n",
              "      <td>3.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.89822</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631</td>\n",
              "      <td>4.970</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.3325</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>375.52</td>\n",
              "      <td>3.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.515</td>\n",
              "      <td>6.037</td>\n",
              "      <td>34.5</td>\n",
              "      <td>5.9853</td>\n",
              "      <td>5.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>8.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.69311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.713</td>\n",
              "      <td>6.376</td>\n",
              "      <td>88.4</td>\n",
              "      <td>2.5671</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>391.43</td>\n",
              "      <td>14.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...   RAD    TAX  PTRATIO       B  LSTAT\n",
              "0  1.23247   0.0   8.14   0.0  0.538  ...   4.0  307.0     21.0  396.90  18.72\n",
              "1  0.02177  82.5   2.03   0.0  0.415  ...   2.0  348.0     14.7  395.38   3.11\n",
              "2  4.89822   0.0  18.10   0.0  0.631  ...  24.0  666.0     20.2  375.52   3.26\n",
              "3  0.03961   0.0   5.19   0.0  0.515  ...   5.0  224.0     20.2  396.90   8.01\n",
              "4  3.69311   0.0  18.10   0.0  0.713  ...  24.0  666.0     20.2  391.43  14.65\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjFkgs7lU-Wi",
        "outputId": "938ad494-5590-468e-ea08-6371b89883e4"
      },
      "source": [
        "print(train_data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.01100e-02 8.00000e+01 1.52000e+00 ... 1.26000e+01 3.96900e+02\n",
            "  4.08000e+00]\n",
            " [1.28023e+01 0.00000e+00 1.81000e+01 ... 2.02000e+01 2.40520e+02\n",
            "  2.37900e+01]\n",
            " [9.82349e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.96900e+02\n",
            "  2.12400e+01]\n",
            " ...\n",
            " [3.52330e-01 0.00000e+00 2.18900e+01 ... 2.12000e+01 3.94080e+02\n",
            "  1.45900e+01]\n",
            " [9.92485e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.88520e+02\n",
            "  1.64400e+01]\n",
            " [1.38100e-02 8.00000e+01 4.60000e-01 ... 1.44000e+01 3.94230e+02\n",
            "  2.97000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2vaKEEEupEs"
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "std = train_data.std(axis=0)\n",
        "\n",
        "train_data = (train_data - mean)/std\n",
        "test_data = (test_data - mean)/std"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "AIHoyG4QaI_F",
        "outputId": "1e12989b-0b2b-439c-bf7c-cc794b60aeae"
      },
      "source": [
        "df = pd.DataFrame(train_data, columns=column_names)\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.418696</td>\n",
              "      <td>2.640856</td>\n",
              "      <td>-1.347353</td>\n",
              "      <td>-0.234159</td>\n",
              "      <td>-1.240199</td>\n",
              "      <td>1.405745</td>\n",
              "      <td>-1.205305</td>\n",
              "      <td>1.585849</td>\n",
              "      <td>-0.837121</td>\n",
              "      <td>-0.468875</td>\n",
              "      <td>-2.547922</td>\n",
              "      <td>0.444622</td>\n",
              "      <td>-1.173902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.976060</td>\n",
              "      <td>-0.541147</td>\n",
              "      <td>1.051083</td>\n",
              "      <td>-0.234159</td>\n",
              "      <td>1.640675</td>\n",
              "      <td>-0.554424</td>\n",
              "      <td>1.025661</td>\n",
              "      <td>-0.958060</td>\n",
              "      <td>1.708322</td>\n",
              "      <td>1.574022</td>\n",
              "      <td>0.778950</td>\n",
              "      <td>-1.296347</td>\n",
              "      <td>1.501586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.650512</td>\n",
              "      <td>-0.541147</td>\n",
              "      <td>1.051083</td>\n",
              "      <td>-0.234159</td>\n",
              "      <td>1.049067</td>\n",
              "      <td>0.731381</td>\n",
              "      <td>1.104191</td>\n",
              "      <td>-1.210694</td>\n",
              "      <td>1.708322</td>\n",
              "      <td>1.574022</td>\n",
              "      <td>0.778950</td>\n",
              "      <td>0.444622</td>\n",
              "      <td>1.155442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.404345</td>\n",
              "      <td>-0.541147</td>\n",
              "      <td>-0.567644</td>\n",
              "      <td>-0.234159</td>\n",
              "      <td>-0.862942</td>\n",
              "      <td>-0.789699</td>\n",
              "      <td>-1.216014</td>\n",
              "      <td>0.547966</td>\n",
              "      <td>-0.721419</td>\n",
              "      <td>-1.050828</td>\n",
              "      <td>-0.227866</td>\n",
              "      <td>0.444622</td>\n",
              "      <td>-0.341799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.410585</td>\n",
              "      <td>-0.541147</td>\n",
              "      <td>-0.328958</td>\n",
              "      <td>-0.234159</td>\n",
              "      <td>-0.245612</td>\n",
              "      <td>0.713599</td>\n",
              "      <td>0.122566</td>\n",
              "      <td>-0.506694</td>\n",
              "      <td>-0.490015</td>\n",
              "      <td>-0.135465</td>\n",
              "      <td>1.085372</td>\n",
              "      <td>0.429927</td>\n",
              "      <td>-0.686586</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CRIM        ZN     INDUS  ...   PTRATIO         B     LSTAT\n",
              "0 -0.418696  2.640856 -1.347353  ... -2.547922  0.444622 -1.173902\n",
              "1  0.976060 -0.541147  1.051083  ...  0.778950 -1.296347  1.501586\n",
              "2  0.650512 -0.541147  1.051083  ...  0.778950  0.444622  1.155442\n",
              "3 -0.404345 -0.541147 -0.567644  ... -0.227866  0.444622 -0.341799\n",
              "4 -0.410585 -0.541147 -0.328958  ...  1.085372  0.429927 -0.686586\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVkbww9MIDZP",
        "outputId": "2f8587ee-b21a-425f-d84a-73a47d0f2cf3"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(13,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='mse', optimizer=Adam(lr=0.001), metrics=['mae'])\n",
        "\n",
        "# 設定Early Stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "print(train_data)\n",
        "print(train_labels)\n",
        "\n",
        "# 訓練模型\n",
        "history = model.fit(train_data, train_labels, batch_size=32, epochs=500, validation_split=0.2, callbacks=[early_stop])\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.41869575  2.64085581 -1.34735288 ... -2.54792177  0.4446223\n",
            "  -1.17390213]\n",
            " [ 0.97606041 -0.54114728  1.05108255 ...  0.77895002 -1.29634669\n",
            "   1.50158634]\n",
            " [ 0.65051177 -0.54114728  1.05108255 ...  0.77895002  0.4446223\n",
            "   1.15544247]\n",
            " ...\n",
            " [-0.3845738  -0.54114728  1.59933769 ...  1.2166963   0.41322741\n",
            "   0.25275357]\n",
            " [ 0.66158922 -0.54114728  1.05108255 ...  0.77895002  0.35132827\n",
            "   0.50387755]\n",
            " [-0.42157003  2.64085581 -1.50069073 ... -1.75997845  0.41489735\n",
            "  -1.32457652]]\n",
            "[33.3 10.8 13.3 19.3 26.5 19.1 18.9 13.9 23.3 24.3 15.  44.  19.5 12.8\n",
            " 38.7 32.7 13.9 19.  22.8 48.8 23.9 20.6 18.2 10.5 20.  12.7 26.6 12.8\n",
            " 23.4 30.5 25.  24.1 23.6  6.3 33.2 17.8 21.4 28.7 15.1 24.1 20.4 23.7\n",
            " 19.4 43.5 20.8  8.8 15.  13.8 33.1 13.2 12.3 28.6 17.  32.  50.  23.1\n",
            " 13.5 22.9 25.  15.2 18.5 45.4 21.1 11.9 20.3 25.3 24.1 11.8 23.1 22.\n",
            " 20.8 14.5 24.  24.7  8.4 29.4 11.7 23.5 33.8 17.4 14.2 22.1 36.2  8.3\n",
            " 22.  18.5 22.9 20.6 22.2 33.8 50.  19.3 21.7 41.3 19.3 18.7 17.2 19.\n",
            " 23.9 13.4 19.2 27.5 13.6 15.2 50.  22.  20.6 21.1 18.5 23.9 20.1 19.2\n",
            " 34.6 15.  17.5 16.4 15.  32.7 11.9 19.3 28.7 17.2 20.4 13.9 14.1 15.3\n",
            " 17.2 18.9 13.6 16.8 36.4 30.8 23.2 18.9 17.5 23.3  8.7 14.4 33.3 23.7\n",
            " 10.8 28.7 18.2 19.4 14.9 18.7 22.9 15.6 24.7 34.9 10.5 16.7 30.5 21.4\n",
            " 23.7 20.3  5.  18.5 19.4 34.9 33.3 18.1 16.  23.9 11.7 21.2 22.1 18.7\n",
            " 33.4 13.3 18.9  8.3 11.8 16.3 15.6 26.2 36.1 23.6 10.8 23.7 12.7 35.2\n",
            " 20.4 13.3  7.2 22.2 20.1 20.3 27.5 36.1 17.3 10.9 30.1 22.7 18.4 22.2\n",
            " 43.5 11.5 44.  22.2 18.4 24.8 18.8 20.5 12.7 18.5 17.8 28.  32.  21.4\n",
            " 10.5 26.4 16.7 27.5 29.8 44.  16.4 29.1 26.6 17.4 24.7 18.7 10.4 22.6\n",
            " 13.9 19.2 22.3 43.5 18.7 26.6 27.1 19.4 16.1 12.8 17.5 22.8 17.4 24.8\n",
            " 20.6 23.1 24.3 18.3 44.8 19.9 13.9 13.2 14.9 30.7 16.  13.4  6.3 31.1\n",
            " 19.6 17.2 21.7 50.  19.5 24.8 20.4  8.4 28.  11.9 19.1 14.5 18.1 50.\n",
            " 12.8 20.8 24.4 15.2 10.4 35.2 18.2 13.8 23.9 23.6 50.  24.4 21.4 34.7\n",
            " 18.4 19.1 27.5 24.  26.5 13.8 19.3 29.  28.6  8.8 21.2 31.5 50.   8.8\n",
            " 13.1 19.4 22.2 22.6 20.5 17.2 10.8 23.1 50.  20.1 20.  13.1 24.5 19.5\n",
            " 22.7 32.  22.2 29.1 13.6 11.7 14.6 34.7 30.7 21.4 20.1 17.4 36.2 32.7\n",
            " 13.9 23.3 18.1 13.6 21.7 19.1 20.1 13.3 39.8 16.2 15.7 10.5 23.3 19.4\n",
            " 32.  28.7 22.  50.  28.  34.7 24.5 18.4  9.6 42.3 14.4 21.9 22.9 33.2\n",
            " 31.6 17.1 29.  36.4 44.  18.  28.7 13.8 15.6 19.2 22.8 19.1 18.2 16.7\n",
            " 26.5 17.8  8.3 23.  23.7 34.6 11.  50.  20.5 24.8 19.6 22.9 23.1 20.6\n",
            " 24.1 23.5 17.5 22.  19.8 23.  20.4 15.3 31.7 37.6 25.1 17.5 17.8 13.1\n",
            " 21.8 19.7 26.6 22.9 31.1 21.1 22.2 37.6 19.3 17.1 12.6 50. ]\n",
            "Epoch 1/500\n",
            "11/11 [==============================] - 1s 23ms/step - loss: 570.5814 - mae: 22.0672 - val_loss: 570.6409 - val_mae: 22.2544\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 501.3313 - mae: 20.5455 - val_loss: 503.6532 - val_mae: 20.8778\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 418.3972 - mae: 18.7379 - val_loss: 427.1887 - val_mae: 19.1440\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 395.5087 - mae: 17.8570 - val_loss: 335.3033 - val_mae: 16.7928\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 303.2204 - mae: 15.2127 - val_loss: 234.0816 - val_mae: 13.7020\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 225.4268 - mae: 12.7260 - val_loss: 134.4315 - val_mae: 9.9445\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 135.2915 - mae: 9.4408 - val_loss: 70.6503 - val_mae: 7.0835\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 106.9831 - mae: 7.7764 - val_loss: 48.9950 - val_mae: 5.9414\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 81.0812 - mae: 6.5954 - val_loss: 43.6338 - val_mae: 5.3866\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 55.4996 - mae: 5.7602 - val_loss: 32.4260 - val_mae: 4.6655\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 46.7592 - mae: 5.1902 - val_loss: 24.1429 - val_mae: 4.0415\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.8233 - mae: 4.4784 - val_loss: 19.7852 - val_mae: 3.6370\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.9755 - mae: 4.2096 - val_loss: 17.0262 - val_mae: 3.3645\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.7659 - mae: 4.1725 - val_loss: 15.8359 - val_mae: 3.3257\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.4473 - mae: 3.7863 - val_loss: 14.0176 - val_mae: 3.0934\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 32.2128 - mae: 3.8799 - val_loss: 13.2996 - val_mae: 3.0074\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 26.1469 - mae: 3.5598 - val_loss: 12.8700 - val_mae: 2.9848\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 22.1563 - mae: 3.4131 - val_loss: 12.4108 - val_mae: 2.8967\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.6108 - mae: 3.3880 - val_loss: 11.8579 - val_mae: 2.8180\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 21.2894 - mae: 3.2867 - val_loss: 11.4957 - val_mae: 2.7494\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 21.1882 - mae: 3.3276 - val_loss: 11.3380 - val_mae: 2.7629\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.5074 - mae: 3.1220 - val_loss: 10.8190 - val_mae: 2.7092\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 19.2508 - mae: 3.0845 - val_loss: 10.3968 - val_mae: 2.6722\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.6149 - mae: 3.1113 - val_loss: 9.8992 - val_mae: 2.5316\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.8058 - mae: 2.8197 - val_loss: 10.2557 - val_mae: 2.4800\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.1542 - mae: 3.0920 - val_loss: 11.0852 - val_mae: 2.6961\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 19.3474 - mae: 3.1642 - val_loss: 10.0810 - val_mae: 2.5592\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.0187 - mae: 2.9274 - val_loss: 9.2455 - val_mae: 2.3966\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.8521 - mae: 2.9742 - val_loss: 8.9324 - val_mae: 2.3566\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.9152 - mae: 2.6988 - val_loss: 8.7204 - val_mae: 2.3524\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.8565 - mae: 2.6860 - val_loss: 9.6067 - val_mae: 2.4753\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 17.1835 - mae: 2.9593 - val_loss: 10.6913 - val_mae: 2.5857\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.2966 - mae: 2.9395 - val_loss: 9.0553 - val_mae: 2.3723\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.9793 - mae: 2.9206 - val_loss: 8.2786 - val_mae: 2.2749\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.6328 - mae: 2.7049 - val_loss: 7.9797 - val_mae: 2.2330\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.3905 - mae: 2.5204 - val_loss: 8.0491 - val_mae: 2.2454\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.4158 - mae: 2.7582 - val_loss: 8.1314 - val_mae: 2.2643\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.2567 - mae: 2.6052 - val_loss: 7.8184 - val_mae: 2.2125\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.4513 - mae: 2.6143 - val_loss: 7.3514 - val_mae: 2.1239\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.2413 - mae: 2.5869 - val_loss: 7.2920 - val_mae: 2.1173\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.3617 - mae: 2.8511 - val_loss: 7.3284 - val_mae: 2.1252\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.5232 - mae: 2.5843 - val_loss: 7.0751 - val_mae: 2.0832\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7538 - mae: 2.3960 - val_loss: 6.8841 - val_mae: 2.0501\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.9389 - mae: 2.4433 - val_loss: 6.6490 - val_mae: 2.0135\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4769 - mae: 2.3713 - val_loss: 6.6948 - val_mae: 2.0062\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.0824 - mae: 2.4557 - val_loss: 6.6489 - val_mae: 2.0059\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.6362 - mae: 2.5147 - val_loss: 6.7987 - val_mae: 2.0241\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8816 - mae: 2.3487 - val_loss: 6.5063 - val_mae: 1.9859\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1398 - mae: 2.3990 - val_loss: 6.7410 - val_mae: 2.0158\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7847 - mae: 2.4311 - val_loss: 6.3532 - val_mae: 1.9532\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.4947 - mae: 2.5172 - val_loss: 6.2651 - val_mae: 1.9440\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9732 - mae: 2.3518 - val_loss: 6.0242 - val_mae: 1.8795\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.9074 - mae: 2.3666 - val_loss: 6.0991 - val_mae: 1.8880\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5797 - mae: 2.2672 - val_loss: 6.1775 - val_mae: 1.9213\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3216 - mae: 2.3950 - val_loss: 5.9916 - val_mae: 1.8823\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5046 - mae: 2.2619 - val_loss: 5.8738 - val_mae: 1.8500\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.6067 - mae: 2.4800 - val_loss: 6.0333 - val_mae: 1.9000\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.5213 - mae: 2.3509 - val_loss: 6.0714 - val_mae: 1.9113\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2066 - mae: 2.4295 - val_loss: 5.9873 - val_mae: 1.8938\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.6667 - mae: 2.3490 - val_loss: 5.8442 - val_mae: 1.8498\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.4317 - mae: 2.4139 - val_loss: 6.0059 - val_mae: 1.8929\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.6320 - mae: 2.4497 - val_loss: 5.9803 - val_mae: 1.8893\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9882 - mae: 2.3300 - val_loss: 5.8021 - val_mae: 1.8484\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6077 - mae: 2.2006 - val_loss: 5.6647 - val_mae: 1.8527\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7965 - mae: 2.3258 - val_loss: 5.8519 - val_mae: 1.8847\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4494 - mae: 2.1902 - val_loss: 5.6936 - val_mae: 1.8327\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.6224 - mae: 2.2911 - val_loss: 5.7209 - val_mae: 1.8492\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9539 - mae: 2.2079 - val_loss: 5.8627 - val_mae: 1.8724\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8275 - mae: 2.3314 - val_loss: 6.0276 - val_mae: 1.8597\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.6068 - mae: 2.3526 - val_loss: 5.8707 - val_mae: 1.8608\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8346 - mae: 2.2224 - val_loss: 5.9261 - val_mae: 1.8797\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4422 - mae: 2.3022 - val_loss: 5.5408 - val_mae: 1.7859\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0418 - mae: 2.1716 - val_loss: 5.5785 - val_mae: 1.8135\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.7293 - mae: 2.0596 - val_loss: 5.5220 - val_mae: 1.7867\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3412 - mae: 2.2452 - val_loss: 5.6085 - val_mae: 1.8267\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8346 - mae: 2.0896 - val_loss: 5.6340 - val_mae: 1.8263\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.0984 - mae: 2.0730 - val_loss: 5.8533 - val_mae: 1.8547\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1359 - mae: 2.2593 - val_loss: 6.8295 - val_mae: 2.0094\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9866 - mae: 2.3099 - val_loss: 5.7481 - val_mae: 1.8255\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.3446 - mae: 2.3058 - val_loss: 5.6981 - val_mae: 1.8237\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.7889 - mae: 2.1663 - val_loss: 5.6997 - val_mae: 1.8290\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0326 - mae: 2.1317 - val_loss: 5.6873 - val_mae: 1.8313\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.0736 - mae: 2.4149 - val_loss: 6.9528 - val_mae: 2.0048\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1078 - mae: 2.1822 - val_loss: 5.7421 - val_mae: 1.8109\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7571 - mae: 2.1318 - val_loss: 5.6567 - val_mae: 1.8095\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8769 - mae: 2.1905 - val_loss: 5.5958 - val_mae: 1.7990\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7455 - mae: 2.3237 - val_loss: 5.9057 - val_mae: 1.8324\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2980 - mae: 2.1119 - val_loss: 5.7660 - val_mae: 1.8382\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0532 - mae: 2.1451 - val_loss: 5.5917 - val_mae: 1.7920\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8052 - mae: 2.0874 - val_loss: 5.6005 - val_mae: 1.7908\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4973 - mae: 2.0945 - val_loss: 5.4241 - val_mae: 1.7535\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6191 - mae: 2.1371 - val_loss: 5.3787 - val_mae: 1.7527\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5461 - mae: 2.0338 - val_loss: 5.4868 - val_mae: 1.7696\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7373 - mae: 2.0998 - val_loss: 5.3745 - val_mae: 1.7410\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3429 - mae: 2.0246 - val_loss: 5.1972 - val_mae: 1.7016\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2747 - mae: 2.0359 - val_loss: 5.5813 - val_mae: 1.7826\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.3840 - mae: 2.1157 - val_loss: 5.4213 - val_mae: 1.7479\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3832 - mae: 1.9983 - val_loss: 5.4635 - val_mae: 1.7548\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1531 - mae: 2.1307 - val_loss: 5.3613 - val_mae: 1.7401\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2192 - mae: 1.9532 - val_loss: 5.1853 - val_mae: 1.7005\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5948 - mae: 1.9921 - val_loss: 5.1867 - val_mae: 1.7067\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9811 - mae: 2.0479 - val_loss: 5.3309 - val_mae: 1.7241\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8216 - mae: 2.0636 - val_loss: 5.2962 - val_mae: 1.7123\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5572 - mae: 1.9855 - val_loss: 5.3093 - val_mae: 1.7154\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8570 - mae: 1.9540 - val_loss: 5.2704 - val_mae: 1.7021\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6858 - mae: 1.9971 - val_loss: 5.2683 - val_mae: 1.7119\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5473 - mae: 2.0698 - val_loss: 5.2111 - val_mae: 1.7045\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9047 - mae: 2.0352 - val_loss: 5.1755 - val_mae: 1.7012\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0681 - mae: 1.9418 - val_loss: 5.3861 - val_mae: 1.7566\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7664 - mae: 1.9248 - val_loss: 5.5790 - val_mae: 1.8216\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7734 - mae: 1.9014 - val_loss: 5.2823 - val_mae: 1.7350\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3687 - mae: 1.9621 - val_loss: 5.5914 - val_mae: 1.7651\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8414 - mae: 1.9804 - val_loss: 5.4240 - val_mae: 1.7418\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2923 - mae: 2.0063 - val_loss: 5.3593 - val_mae: 1.7372\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5879 - mae: 1.8847 - val_loss: 5.3766 - val_mae: 1.7425\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9034 - mae: 1.9570 - val_loss: 5.1821 - val_mae: 1.7025\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2308 - mae: 1.9163 - val_loss: 5.6205 - val_mae: 1.8227\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4346 - mae: 2.0346 - val_loss: 5.1924 - val_mae: 1.6970\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8072 - mae: 1.9327 - val_loss: 5.1515 - val_mae: 1.6751\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1859 - mae: 1.9525 - val_loss: 5.2068 - val_mae: 1.7091\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4019 - mae: 1.8469 - val_loss: 6.2720 - val_mae: 1.8942\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9191 - mae: 2.0021 - val_loss: 5.5679 - val_mae: 1.7858\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6582 - mae: 1.9470 - val_loss: 5.8377 - val_mae: 1.8610\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4775 - mae: 1.9669 - val_loss: 5.2947 - val_mae: 1.7189\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7540 - mae: 1.9523 - val_loss: 5.3967 - val_mae: 1.7549\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5525 - mae: 1.8708 - val_loss: 5.1790 - val_mae: 1.6762\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2233 - mae: 1.8949 - val_loss: 5.4992 - val_mae: 1.7547\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3515 - mae: 1.8581 - val_loss: 5.2919 - val_mae: 1.6947\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8735 - mae: 1.7670 - val_loss: 5.1508 - val_mae: 1.6743\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8817 - mae: 1.8793 - val_loss: 5.4047 - val_mae: 1.7171\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3403 - mae: 1.9224 - val_loss: 5.4370 - val_mae: 1.7151\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7023 - mae: 1.7743 - val_loss: 5.0935 - val_mae: 1.6649\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1918 - mae: 1.7892 - val_loss: 5.2096 - val_mae: 1.6920\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7679 - mae: 1.9364 - val_loss: 5.3691 - val_mae: 1.7025\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9193 - mae: 1.8495 - val_loss: 5.2417 - val_mae: 1.6824\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0563 - mae: 1.8460 - val_loss: 5.3526 - val_mae: 1.6983\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6704 - mae: 1.9803 - val_loss: 5.3324 - val_mae: 1.7009\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6236 - mae: 1.8244 - val_loss: 5.2569 - val_mae: 1.6952\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5432 - mae: 1.8736 - val_loss: 5.4558 - val_mae: 1.7471\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8940 - mae: 1.8927 - val_loss: 5.5983 - val_mae: 1.7639\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6599 - mae: 1.8430 - val_loss: 5.2710 - val_mae: 1.6996\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7219 - mae: 1.8710 - val_loss: 5.1798 - val_mae: 1.6852\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4768 - mae: 1.9680 - val_loss: 4.9946 - val_mae: 1.6565\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2009 - mae: 1.8451 - val_loss: 5.2659 - val_mae: 1.7272\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0600 - mae: 1.7910 - val_loss: 5.6308 - val_mae: 1.7977\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4467 - mae: 1.7516 - val_loss: 5.2277 - val_mae: 1.7039\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6486 - mae: 1.9033 - val_loss: 5.3104 - val_mae: 1.7091\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5708 - mae: 1.8121 - val_loss: 5.3318 - val_mae: 1.7258\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2478 - mae: 2.0021 - val_loss: 5.5640 - val_mae: 1.7482\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.6711 - mae: 1.6923 - val_loss: 5.1174 - val_mae: 1.6828\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.0868 - mae: 1.7407 - val_loss: 5.1708 - val_mae: 1.6775\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8393 - mae: 1.7599 - val_loss: 5.5654 - val_mae: 1.7460\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4267 - mae: 1.7595 - val_loss: 5.1651 - val_mae: 1.6720\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5955 - mae: 1.7263 - val_loss: 5.1923 - val_mae: 1.6783\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3648 - mae: 1.9562 - val_loss: 5.3578 - val_mae: 1.7618\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3307 - mae: 1.7469 - val_loss: 5.1700 - val_mae: 1.7071\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7517 - mae: 1.7835 - val_loss: 5.1251 - val_mae: 1.6779\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2193 - mae: 1.8098 - val_loss: 5.1679 - val_mae: 1.6940\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1956 - mae: 1.7365 - val_loss: 5.3288 - val_mae: 1.6893\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3234 - mae: 1.7345 - val_loss: 5.1931 - val_mae: 1.6754\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.0623 - mae: 1.6922 - val_loss: 5.1186 - val_mae: 1.6780\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.1311 - mae: 1.8091 - val_loss: 5.2182 - val_mae: 1.6857\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4148 - mae: 1.7611 - val_loss: 4.9068 - val_mae: 1.6318\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4698 - mae: 1.7411 - val_loss: 4.9404 - val_mae: 1.6417\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1918 - mae: 1.8283 - val_loss: 5.1611 - val_mae: 1.6909\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1102 - mae: 1.7971 - val_loss: 4.9518 - val_mae: 1.6356\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1084 - mae: 1.7014 - val_loss: 5.0831 - val_mae: 1.6853\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1840 - mae: 1.8497 - val_loss: 5.2141 - val_mae: 1.6873\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9323 - mae: 1.6557 - val_loss: 4.8569 - val_mae: 1.6099\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5511 - mae: 1.7668 - val_loss: 4.9149 - val_mae: 1.6287\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3137 - mae: 1.7347 - val_loss: 4.9544 - val_mae: 1.6350\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9297 - mae: 1.6445 - val_loss: 5.0031 - val_mae: 1.6674\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.3988 - mae: 1.6932 - val_loss: 4.9005 - val_mae: 1.6346\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5466 - mae: 1.7737 - val_loss: 5.0130 - val_mae: 1.6759\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9985 - mae: 1.8127 - val_loss: 4.8514 - val_mae: 1.6206\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8576 - mae: 1.7146 - val_loss: 4.7550 - val_mae: 1.6172\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.0594 - mae: 1.9516 - val_loss: 5.0288 - val_mae: 1.7066\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.1545 - mae: 1.7030 - val_loss: 5.0625 - val_mae: 1.6706\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7405 - mae: 1.7523 - val_loss: 5.1235 - val_mae: 1.6600\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1370 - mae: 1.8157 - val_loss: 5.8244 - val_mae: 1.7646\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2997 - mae: 1.7272 - val_loss: 5.2486 - val_mae: 1.6795\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4004 - mae: 1.7021 - val_loss: 5.2105 - val_mae: 1.6702\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2891 - mae: 1.7225 - val_loss: 4.9463 - val_mae: 1.6321\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1802 - mae: 1.6637 - val_loss: 5.2889 - val_mae: 1.7395\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3252 - mae: 1.7359 - val_loss: 5.0205 - val_mae: 1.6360\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4578 - mae: 1.6979 - val_loss: 4.9849 - val_mae: 1.6352\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3010 - mae: 1.6335 - val_loss: 4.9887 - val_mae: 1.6530\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7013 - mae: 1.5901 - val_loss: 5.0660 - val_mae: 1.6788\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.9234 - mae: 1.6338 - val_loss: 4.8173 - val_mae: 1.6077\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.5935 - mae: 1.6149 - val_loss: 5.0733 - val_mae: 1.6784\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2431 - mae: 1.6001 - val_loss: 5.1864 - val_mae: 1.7066\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.2943 - mae: 1.6111 - val_loss: 5.0848 - val_mae: 1.6666\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.0014 - mae: 1.6319 - val_loss: 4.9300 - val_mae: 1.6341\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.4962 - mae: 1.5600 - val_loss: 5.0094 - val_mae: 1.6927\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1866 - mae: 1.6689 - val_loss: 5.1882 - val_mae: 1.6749\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5935 - mae: 1.6925 - val_loss: 5.1045 - val_mae: 1.6736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "UoTpEm8DkfqU",
        "outputId": "672de7e8-0707-40f5-9db3-8625de3886b0"
      },
      "source": [
        "plt.plot(history.history['mae'], label='train mae')\n",
        "plt.plot(history.history['val_mae'], label='val mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('mae')\n",
        "plt.legend(loc='best')\n",
        "plt.ylim([0, 5])\n",
        "plt.show()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-9KqrJzoF1z",
        "outputId": "9ef0786b-2d95-4eea-cdc2-a836ca6d7519"
      },
      "source": [
        "test_loss, test_mae = model.evaluate(test_data, test_labels)\n",
        "print('loss:{:.3f}\\nmae:{:.3f}'.format(test_loss, test_mae))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 22.5494 - mae: 3.0535\n",
            "loss:22.549\n",
            "mae:3.054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OvUIq2Uodf7",
        "outputId": "e1a50ad1-e137-4aa0-dd48-8af555d246e4"
      },
      "source": [
        "print('前10筆測試標籤:', np.round(test_labels[0:10]))\n",
        "test_predictions = model.predict(test_data[0:10]).flatten()\n",
        "print('前10比預測結果:', np.round(test_predictions))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "前10筆測試標籤: [ 7. 19. 19. 27. 22. 24. 31. 23. 20. 23.]\n",
            "前10比預測結果: [ 9. 18. 22. 35. 25. 20. 27. 23. 20. 27.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}